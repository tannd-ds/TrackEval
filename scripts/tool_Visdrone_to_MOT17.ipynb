{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f769d44-9958-4a25-8fa9-8167bf3434c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def handle_subset(subset, from_path, to_path):\n",
    "    print(f'Making data for {subset} set...')\n",
    "    os.mkdir(os.path.join(to_path, subset))\n",
    "  \n",
    "    for seq_name in os.listdir(os.path.join(from_path, subset, 'sequences')):\n",
    "        print(f'copying {seq_name}...')\n",
    "\n",
    "        current_dir = os.path.join(to_path, subset, seq_name)\n",
    "        \n",
    "        os.mkdir(current_dir)\n",
    "     \n",
    "        # create gt, det, img1 directories\n",
    "        dirs = ['gt', 'det', 'img1']\n",
    "        for dir_ in dirs:\n",
    "            os.mkdir(os.path.join(current_dir, dir_))\n",
    "\n",
    "        # Copy annotation file from visdrone to gt folder, then rename it to 'gt.txt'\n",
    "        shutil.copy(\n",
    "            os.path.join(from_path, subset, 'annotations', f'{seq_name}.txt'), \n",
    "            os.path.join(current_dir, 'gt')\n",
    "        )        \n",
    "\n",
    "        os.rename(\n",
    "            os.path.join(current_dir, 'gt', f'{seq_name}.txt'),\n",
    "            os.path.join(current_dir, 'gt', 'gt.txt')\n",
    "        )\n",
    "\n",
    "        # Copy annotation file from visdrone to gt folder, then rename it to 'det.txt'\n",
    "        # This is currently use gt to \"simulate\" det\n",
    "        # TODO: Find better solution.\n",
    "        shutil.copy(\n",
    "            os.path.join(from_path, subset, 'annotations', f'{seq_name}.txt'), \n",
    "            os.path.join(current_dir, 'det')\n",
    "        )        \n",
    "\n",
    "        os.rename(\n",
    "            os.path.join(current_dir, 'det', f'{seq_name}.txt'),\n",
    "            os.path.join(current_dir, 'det', 'det.txt')\n",
    "        )\n",
    "\n",
    "        seq_dir = os.path.join(from_path, subset, 'sequences', seq_name)\n",
    "        for frame in os.listdir(seq_dir):\n",
    "            shutil.copy(\n",
    "                os.path.join(seq_dir, frame), \n",
    "                os.path.join(current_dir, 'img1')\n",
    "            )\n",
    "\n",
    "def visdrone_to_mot17(visdrone_path: str):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    ----------\n",
    "    visdrone_path: str, required\n",
    "        relative path to visdrone dataset directory.\n",
    "    \"\"\"\n",
    "    parent_dir = os.path.dirname(visdrone_path)\n",
    "    visdrone_coco_dir = os.path.join(parent_dir, os.path.basename(visdrone_path) + '_coco')\n",
    "\n",
    "    # Create root directory\n",
    "    try:\n",
    "        os.mkdir(visdrone_coco_dir)\n",
    "    except FileExistsError:\n",
    "        print(f'Stopped. Make sure folder {visdrone_coco_dir} directory is empty.')\n",
    "        return\n",
    "\n",
    "    handle_subset(subset='train', from_path=visdrone_path, to_path=visdrone_coco_dir)\n",
    "    handle_subset(subset='test', from_path=visdrone_path, to_path=visdrone_coco_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275edca-e2a2-42d7-8239-2dcd849a8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "visdrone_to_mot17('../datasets/VisDrone2019-MOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3038c8c6-e5fb-4d7a-b15d-650d40138b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove directory \n",
    "shutil.rmtree('../datasets/VisDrone2019-MOT_coco')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf9c1e-48f4-44b9-ab89-350044431cbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MOT17 TO COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4d7ee95c-b7db-4e70-b919-2de45262333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/VisDrone2019-MOT_coco/train/uav0000013_00000_v/img1/000001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@141.791] global loadsave.cpp:241 findDecoder imread_('../datasets/VisDrone2019-MOT_coco/train/uav0000013_00000_v/img1/000001.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/img1/\u001b[39m\u001b[38;5;132;01m{:06d}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(seq, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     57\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/img1/\u001b[39m\u001b[38;5;132;01m{:06d}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(seq, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 58\u001b[0m height, width \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     59\u001b[0m image_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/img1/\u001b[39m\u001b[38;5;132;01m{:06d}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(seq, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),  \u001b[38;5;66;03m# image name.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: image_cnt \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# image number in the entire training set.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m image_range[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# image number in the video sequence, starting from 1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m: video_cnt,\n\u001b[1;32m     65\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m: height, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: width}\n\u001b[1;32m     66\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(image_info)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Use the same script for MOT16\n",
    "DATA_PATH = 'datasets/mot'\n",
    "OUT_PATH = os.path.join(DATA_PATH, 'annotations')\n",
    "SPLITS = ['train_half', 'val_half', 'train', 'test']  # --> split training data to train_half and val_half.\n",
    "HALF_VIDEO = True\n",
    "CREATE_SPLITTED_ANN = True\n",
    "CREATE_SPLITTED_DET = True\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists(OUT_PATH):\n",
    "        os.makedirs(OUT_PATH)\n",
    "\n",
    "    for split in SPLITS:\n",
    "        if split == \"test\":\n",
    "            data_path = os.path.join(DATA_PATH, 'test')\n",
    "        else:\n",
    "            data_path = os.path.join(DATA_PATH, 'train')\n",
    "        out_path = os.path.join(OUT_PATH, '{}.json'.format(split))\n",
    "        out = {'images': [], 'annotations': [], 'videos': [],\n",
    "               'categories': [\n",
    "                   {'id': 0, 'name': 'ignored_region'},\n",
    "                   {'id': 1, 'name': 'pedestrian'},\n",
    "                   {'id': 2, 'name': 'people'},\n",
    "                   {'id': 3, 'name': 'bicycle'},\n",
    "                   {'id': 4, 'name': 'car'},\n",
    "                   {'id': 5, 'name': 'van'},\n",
    "                   {'id': 6, 'name': 'truck'},\n",
    "                   {'id': 7, 'name': 'tricycle'},\n",
    "                   {'id': 8, 'name': 'awning-tricycle'},\n",
    "                   {'id': 9, 'name': 'bus'},\n",
    "                   {'id': 10, 'name': 'motor'},\n",
    "                   {'id': 11, 'name': 'others'},\n",
    "                ]}\n",
    "        seqs = os.listdir(data_path)\n",
    "        image_cnt = 0\n",
    "        ann_cnt = 0\n",
    "        video_cnt = 0\n",
    "        tid_curr = 0\n",
    "        tid_last = -1\n",
    "        for seq in sorted(seqs):\n",
    "            if '.DS_Store' in seq:\n",
    "                continue\n",
    "            video_cnt += 1  # video sequence number.\n",
    "            out['videos'].append({'id': video_cnt, 'file_name': seq})\n",
    "            seq_path = os.path.join(data_path, seq)\n",
    "            img_path = os.path.join(seq_path, 'img1')\n",
    "            ann_path = os.path.join(seq_path, 'gt/gt.txt')\n",
    "            images = os.listdir(img_path)\n",
    "            num_images = len([image for image in images if 'jpg' in image])  # half and half\n",
    "\n",
    "            if HALF_VIDEO and ('half' in split):\n",
    "                image_range = [0, num_images // 2] if 'train' in split else \\\n",
    "                              [num_images // 2 + 1, num_images - 1]\n",
    "            else:\n",
    "                image_range = [0, num_images - 1]\n",
    "\n",
    "            for i in range(num_images):\n",
    "                if i < image_range[0] or i > image_range[1]:\n",
    "                    continue\n",
    "                img = cv2.imread(os.path.join(data_path, '{}/img1/{:07d}.jpg'.format(seq, i + 1)))\n",
    "                height, width = img.shape[:2]\n",
    "                image_info = {'file_name': '{}/img1/{:07d}.jpg'.format(seq, i + 1),  # image name.\n",
    "                              'id': image_cnt + i + 1,  # image number in the entire training set.\n",
    "                              'frame_id': i + 1 - image_range[0],  # image number in the video sequence, starting from 1.\n",
    "                              'prev_image_id': image_cnt + i if i > 0 else -1,  # image number in the entire training set.\n",
    "                              'next_image_id': image_cnt + i + 2 if i < num_images - 1 else -1,\n",
    "                              'video_id': video_cnt,\n",
    "                              'height': height, 'width': width}\n",
    "                out['images'].append(image_info)\n",
    "            print('{}: {} images'.format(seq, num_images))\n",
    "            if split != 'test':\n",
    "                det_path = os.path.join(seq_path, 'det/det.txt')\n",
    "                anns = np.loadtxt(ann_path, dtype=np.float32, delimiter=',')\n",
    "                dets = np.loadtxt(det_path, dtype=np.float32, delimiter=',')\n",
    "                if CREATE_SPLITTED_ANN and ('half' in split):\n",
    "                    anns_out = np.array([anns[i] for i in range(anns.shape[0])\n",
    "                                         if int(anns[i][0]) - 1 >= image_range[0] and\n",
    "                                         int(anns[i][0]) - 1 <= image_range[1]], np.float32) \n",
    "                    anns_out[:, 0] -= image_range[0]\n",
    "                    gt_out = os.path.join(seq_path, 'gt/gt_{}.txt'.format(split))\n",
    "                    fout = open(gt_out, 'w')\n",
    "                    for o in anns_out:\n",
    "                        fout.write('{:d},{:d},{:d},{:d},{:d},{:d},{:d},{:d},{:.6f}\\n'.format(\n",
    "                                    int(o[0]), int(o[1]), int(o[2]), int(o[3]), int(o[4]), int(o[5]),\n",
    "                                    int(o[6]), int(o[7]), o[8]))\n",
    "                    fout.close()\n",
    "                if CREATE_SPLITTED_DET and ('half' in split):\n",
    "                    dets_out = np.array([dets[i] for i in range(dets.shape[0])\n",
    "                                         if int(dets[i][0]) - 1 >= image_range[0] and\n",
    "                                         int(dets[i][0]) - 1 <= image_range[1]], np.float32)\n",
    "                    dets_out[:, 0] -= image_range[0]\n",
    "                    det_out = os.path.join(seq_path, 'det/det_{}.txt'.format(split))\n",
    "                    dout = open(det_out, 'w')\n",
    "                    for o in dets_out:\n",
    "                        dout.write('{:d},{:d},{:.1f},{:.1f},{:.1f},{:.1f},{:.6f}\\n'.format(\n",
    "                                    int(o[0]), int(o[1]), float(o[2]), float(o[3]), float(o[4]), float(o[5]),\n",
    "                                    float(o[6])))\n",
    "                    dout.close()\n",
    "\n",
    "                print('{} ann images'.format(int(anns[:, 0].max())))\n",
    "                for i in range(anns.shape[0]):\n",
    "                    frame_id = int(anns[i][0])\n",
    "                    if frame_id - 1 < image_range[0] or frame_id - 1 > image_range[1]:\n",
    "                        continue\n",
    "                    track_id = int(anns[i][1])\n",
    "                    cat_id = int(anns[i][7])\n",
    "                    ann_cnt += 1\n",
    "                    #if int(anns[i][7]) in [3, 4, 5, 6, 9, 10, 11]:  # Non-person\n",
    "                    if cat_id in [0]: # Non-person\n",
    "                        continue\n",
    "                    else:\n",
    "                        category_id = cat_id\n",
    "                        if not track_id == tid_last:\n",
    "                            tid_curr += 1\n",
    "                            tid_last = track_id\n",
    "\n",
    "                    ann = {'id': ann_cnt,\n",
    "                           'category_id': category_id,\n",
    "                           'image_id': image_cnt + frame_id,\n",
    "                           'track_id': tid_curr,\n",
    "                           'bbox': anns[i][2:6].tolist(),\n",
    "                           'conf': float(anns[i][6]),\n",
    "                           'iscrowd': 0,\n",
    "                           'area': float(anns[i][4] * anns[i][5])}\n",
    "                    out['annotations'].append(ann)\n",
    "            image_cnt += num_images\n",
    "            print(tid_curr, tid_last)\n",
    "        print('loaded {} for {} images and {} samples'.format(split, len(out['images']), len(out['annotations'])))\n",
    "        json.dump(out, open(out_path, 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
